---
layout: default
---

Check out the competition details below :point_down: 
and be sure to join our Discord server [https://discord.gg/dA8jpFVa9t](https://discord.gg/dA8jpFVa9t) for questions or news :loudspeaker:

# Motivation
Control systems play a vital role in managing and regulating various processes and devices across diverse application domains. 
Their pervasive nature makes them a cornerstone of modern technology. 
Safety-critical applications, in particular, demand control systems that are not only efficient but also interpretable, ensuring trustworthiness, reliability, and accountability.
However, a prevalent issue in the field is the over-reliance on opaque systems, such as deep neural networks, known for their efficiency and optimization potential. 
This preference is rooted in the prevailing belief that interpretability is of secondary importance, with performance taking precedence. 
Furthermore, the scarcity of objective metrics to assess the degree of interpretability in a system exacerbates this problem. 
In fact, though the Evolutionary Computation (EC) community is starting to promote explainable and/or interpretable AI, significant challenges still persist in achieving comprehensive solutions.
The goal of this competition is thus to ignite the research domain of interpretable control, with two specific goals in mind. 
First, we want to create a basis of comparison for different techniques emphasizing the trade-offs between performance and interpretability. 
Second, through the involvement of a panel of human evaluators, we strive to uncover the key characteristics that enhance the interpretability of control policies, making them more accessible to the general user.

# Participation
Participants will be asked to solve a control problem, which we will communicate by the end of January. 
Participants will have the freedom to apply their preferred methods to generate and interpret policies that effectively address the proposed task. 
However, we promote the inclusion of EC techniques into either the policy generation or explanation process, as a valuable component of addressing the proposed task.

Each submission will have to include the following:
- Control Policy: participants will have to submit a control policy of their choice, which can take any form, as long as the participants can provide a clear and coherent explanation for it. 
- Policy Explanation and Pipeline Description (up to 4 pages): this document should contain an interpretability analysis of the policy, covering all relevant information deducible from it. Moreover, it should outline the participant's pipeline for obtaining the control policy and formulating the corresponding explanation. 
- Code for Reproducibility: participants will have to make their code available to enhance transparency and allow others to replicate and build upon the solutions provided.

More details on the submission procedure will follow by the end of January.
In the meanwhile, if you want to ask any question or provide some feedback, join us at our Discord server: [https://discord.gg/dA8jpFVa9t](https://discord.gg/dA8jpFVa9t).

# Submission deadline
13th June 2024.

# Evaluation criteria
The final score for each entry will be determined by combining the two following terms.
- Performance Rank: this will be evaluated by simulating the submitted policy to assess its effectiveness in solving the given problem.
- Interpretability Rank: this aspect will be appraised by a panel of judges. In determining the interpretability rank, we will draw inspiration from the criteria established for the Symbolic Regression Competition. The guidelines provided to the jury will include the following considerations:
  - Clarity of the pipeline
  - Readability of the model
  - Clarity of the explanation provided
  - Amount of processing required to derive the explanation from the raw policy

These two ranks will be combined using the geometric mean to compute the overall global rank for each competition entry.

# Results and dissemination
Our objective is to raise awareness regarding the importance of interpretability within the realm of control systems. 
To achieve this, we aim at collecting a wide variety of methodologies and publishing the results in a comprehensive report. 
We also plan to extend an invitation to select participants to become co-authors of this publication.

# Prize
The winner(s) will be awarded a certificate. 
We are actively in pursuit of sponsorships to furnish monetary prizes.
If you are interested in the competition and want to become a sponsor, feel free to reach out to any of the organizers!

# Organizers
**Giorgia Nadizar**, University of Trieste, [giorgia.nadizar@phd.units.it](mailto:giorgia.nadizar@phd.units.it) <br>
Giorgia Nadizar is a third year PhD student at the University of Trieste, Italy. 
Her research interests lie at the intersection of embodied AI and explainable/interpretable AI.


**Luigi Rovito**, University of Trieste, [luigi.rovito@phd.units.it](mailto:luigi.rovito@phd.units.it ) <br>
Luigi Rovito is a third year PhD student at the University of Trieste, Italy. 
His research interests are genetic programming for cryptography and interpretable ML.


**Dennis G. Wilson**, ISAE-SUPAERO, University of Toulouse, [dennis.wilson@isae.fr](mailto:dennis.wilson@isae.fr) <br>
Dennis G. Wilson is an Associate Professor at ISAE-Supaero in Toulouse, France. 
They research evolutionary algorithms, deep learning, and applications of AI to climate problems.

**Eric Medvet**, University of Trieste, [emedvet@units.it](mailto:emedvet@units.it) <br>
Eric Medvet is an Associate Professor at the University of Trieste, Italy. 
His research interests include embodied AI, artificial life, and evolutionary optimization.

